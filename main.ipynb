{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96052a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 22:03:30.862790: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 22:03:30.870397: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 22:03:30.892354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-05 22:03:30.926117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-05 22:03:30.936132: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-05 22:03:30.963379: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 22:03:32.911145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1921ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads mnist data into variables\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1254718-3c5b-429f-96dd-370250e7f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264b3b4b-b73c-484b-9090-5ddd3e7044ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel values by default are [0,255] (where 0 is black and 255 is white)\n",
    "# We normalize these values for better compatibility with my model\n",
    "train_images = train_images.astype('float32')/255.0\n",
    "test_images = test_images.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15303d4-12aa-4104-8eeb-beb1b572dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = 2\n",
    "cols = 4\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 5))\n",
    "\n",
    "# Commented code shows first 8 images (indices 0-7)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        index = j + (cols * i)\n",
    "        axes[i, j].imshow(train_images[index], cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "\n",
    "# # Show 8 random images in the dataset\n",
    "# for i in range(rows):\n",
    "#     for j in range(cols):\n",
    "#         index = random.randint(0, train_images.shape[0] - 1)\n",
    "#         axes[i, j].imshow(train_images[index], cmap='gray')\n",
    "#         axes[i, j].axis('off')\n",
    "\n",
    "fig.suptitle(\"MNIST Dataset Sample Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8e8a3e-a415-44fe-bda6-da00a2bdb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defines the neuron class\n",
    "class Neuron:\n",
    "    def __init__(self, activation, z=0.0):\n",
    "        self.activation = activation\n",
    "        self.z = z\n",
    "\n",
    "    def setActivation(self, num):\n",
    "        self.activation = num\n",
    "\n",
    "    def getActivation(self):\n",
    "        return self.activation\n",
    "\n",
    "# Gets the max value from an array of neurons\n",
    "def getMax(l):\n",
    "    _max = l[0].getActivation()\n",
    "    for i in range(1, l.size):\n",
    "        if l[i].getActivation() > _max:\n",
    "            _max = l[i].getActivation()\n",
    "    return _max    \n",
    "\n",
    "# Returns the number (index) which has the highest activation\n",
    "def getMaxNumber(l):\n",
    "    max_act = l[0].getActivation()\n",
    "    max_idx = 0\n",
    "    for i in range(1, l.size):\n",
    "        if l[i].getActivation() > max_act:\n",
    "            max_act = l[i].getActivation()\n",
    "            max_idx = i\n",
    "            \n",
    "    return max_idx\n",
    "\n",
    "# Takes an image (index) and changes the 1st layer of neuron accordingly\n",
    "def fillFirstLayer(l, data, index):\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            l = np.append(l, Neuron(data[index][i][j]))\n",
    "            \n",
    "    return l\n",
    "\n",
    "# Used to initialize layers 2-4\n",
    "def fillLayerWithZeroNeurons(l, num):\n",
    "    for i in range(num):\n",
    "        l = np.append(l, Neuron(0))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e7d4ed-4958-4416-92e9-e169474d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1 will be composed of the pixel values of the image inputted\n",
    "l1 = np.array([])\n",
    "\n",
    "# layers 2-3 will be the 'hidden layers' or 'black box' of the network\n",
    "l2 = np.array([])\n",
    "l3 = np.array([])\n",
    "\n",
    "# layer 4 will be the output layer or the head\n",
    "l4 = np.array([])\n",
    "\n",
    "# initialize the layers here\n",
    "l1 = fillFirstLayer(l1, train_images, 0)\n",
    "l2 = fillLayerWithZeroNeurons(l2, 16)\n",
    "l3 = fillLayerWithZeroNeurons(l3, 16)\n",
    "l4 = fillLayerWithZeroNeurons(l4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7f9c6a-bf28-4140-82e4-c6289f84dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Here we are assigning random weights and biases\n",
    "# After this chunk runs all 13,002 parameters have a value\n",
    "# Weights are between -5 and 5 and biases are between -10 and 10\n",
    "# \"\"\"\n",
    "\n",
    "# l1Weights = np.array([])\n",
    "\n",
    "# for i in range(l1.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l2.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l1Weights.size == 0:\n",
    "#         l1Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l1Weights = np.append(l1Weights, [temp], axis=0)    \n",
    "\n",
    "# print(l1Weights.shape)\n",
    "\n",
    "# l2Weights = np.array([])\n",
    "\n",
    "# for i in range(l2.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l3.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l2Weights.size == 0:\n",
    "#         l2Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l2Weights = np.append(l2Weights, [temp], axis=0)     \n",
    "\n",
    "# print(l2Weights.shape)\n",
    "\n",
    "# l3Weights = np.array([])\n",
    "\n",
    "# for i in range(l3.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l4.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l3Weights.size == 0:\n",
    "#         l3Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l3Weights = np.append(l3Weights, [temp], axis=0)  \n",
    "\n",
    "# print(l3Weights.shape)\n",
    "\n",
    "# l2Biases = np.array([])\n",
    "# l3Biases = np.array([])\n",
    "# l4Biases = np.array([])\n",
    "\n",
    "# for i in range(16):\n",
    "#     l2Biases = np.append(l2Biases, np.random.uniform(-10, 10))\n",
    "#     l3Biases = np.append(l3Biases, np.random.uniform(-10, 10))\n",
    "#     if i < 10:\n",
    "#         l4Biases = np.append(l4Biases, np.random.uniform(-10, 10))\n",
    "\n",
    "# print(l1Weights.size + l2Weights.size + l3Weights.size + l2Biases.size + l3Biases.size + l4Biases.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd05737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 16)\n",
      "[[-3.02267133  0.56047007 -2.72051026 ...  3.85038065  4.29801052\n",
      "   3.63012453]\n",
      " [-0.8659356  -2.79450593  1.97475767 ... -1.81166954  1.76208386\n",
      "  -3.00212061]\n",
      " [ 4.55549678  3.85353515 -4.2519361  ...  1.41362207  4.62731624\n",
      "   3.64891414]\n",
      " ...\n",
      " [-1.51843872 -1.93457698 -0.38490441 ... -4.9019857  -0.99821486\n",
      "  -1.10353037]\n",
      " [-1.84002995  4.22908265 -1.67177566 ... -4.87476663  3.44468856\n",
      "  -0.33344256]\n",
      " [ 3.84556628 -3.62331979  0.30053475 ...  4.63908253  0.34111314\n",
      "   2.55354013]]\n",
      "(16, 16)\n",
      "[[-2.43637475  4.32581321  4.53390649 -4.40843444  1.18677481 -1.99871184\n",
      "   2.83855063  3.22471158 -3.57354802 -2.20605335 -0.33349429  2.23834359\n",
      "  -4.12713653 -3.24541496  1.24914635  1.15392698]\n",
      " [ 2.38282071 -3.11881415 -4.5646954  -2.00755468  2.66499937  0.34957251\n",
      "   0.74958856 -2.91556201 -1.82509145 -3.88151742 -1.09054813  0.24631201\n",
      "  -0.31058617  1.01460817 -1.52252155  1.18805985]\n",
      " [ 2.85285862  1.12290186  2.3423055  -2.0857615   4.15945982  0.30630459\n",
      "   1.42868378 -3.67373222  2.18809871 -1.54615836  4.04669248 -1.01964691\n",
      "  -2.78132734 -3.56857706  4.70450373  3.32634871]\n",
      " [-2.04970571 -4.44422546  3.88820008 -1.65874506 -0.68438346  1.76695802\n",
      "   0.65687764 -1.76967936  1.471577   -2.8591949  -3.24703148 -2.40816335\n",
      "   4.9948042  -3.09557473 -0.72421781 -3.26708932]\n",
      " [ 1.5796247   2.09725229  3.31482152  2.03137369  0.28341892  2.98248206\n",
      "   1.80461805 -1.51827888 -4.96403938 -4.07255227 -1.83656453 -1.24297556\n",
      "   1.50993014 -4.90871551  2.47832845  1.2042155 ]\n",
      " [-0.96070504 -0.91555532 -4.11008691  0.28460467  2.5058201  -2.68261561\n",
      "  -0.07930692  1.49284681 -2.25477917  3.80489905  2.04678063  2.40555939\n",
      "   3.66701436  3.90076845 -2.38439393 -1.93733228]\n",
      " [-2.80503067  3.64244317  1.12430906 -0.26636694 -4.0162616   0.71732616\n",
      "   2.37161343 -0.37778862  3.37785228 -3.12901596 -4.81546759  1.5113968\n",
      "  -4.1181539   4.10544733  1.58780509 -2.21908394]\n",
      " [-3.31707061 -1.11118251 -3.33173142  1.13047471  3.81663151  4.24197454\n",
      "  -4.68131764 -0.51671982 -2.09417716  2.21382053 -2.33912387  2.13870814\n",
      "  -4.97411218  2.32162202  2.04409097 -1.36206978]\n",
      " [-3.91091113  0.22184639  2.75764076 -2.56952772  0.04525263  1.00230104\n",
      "  -4.68491309 -0.72789112 -4.85649772  1.24123486 -3.83753762  4.56074391\n",
      "  -0.03779106  2.84820305  0.50913392  3.07773263]\n",
      " [-1.8786379  -4.62126175 -4.29495816  3.99711805 -4.39281235 -0.30095862\n",
      "  -4.56789792 -1.67817389  2.5173786  -3.55701923  2.71211     3.06106609\n",
      "   2.02332909 -3.68448761 -1.19329238  2.11888443]\n",
      " [-3.67464905  0.37315738 -3.62407796 -2.9949161  -1.45618262  3.03633748\n",
      "   3.99195559 -4.95412647  4.97195198  3.66321423  2.12414098  2.32820221\n",
      "   0.17035251 -4.039219   -2.19478124 -4.82115661]\n",
      " [-3.63434046  3.59329829 -4.78268426  2.44347213 -1.72114248  2.67111838\n",
      "   1.45906389  2.95711668 -0.55604026 -1.41829997  3.49544896 -4.48236479\n",
      "  -3.67053894 -3.8297855  -4.20111472 -4.1594623 ]\n",
      " [ 4.77027928 -3.98397674 -3.42370315  2.05267964  0.56339532 -2.35954819\n",
      "  -3.92918928 -2.20453301  1.14526826  1.60843706  2.43456121  3.2306219\n",
      "  -3.48705626  1.44877662 -3.80992624 -0.50537379]\n",
      " [ 4.95286711 -1.99498729 -3.89145901 -3.7643603  -3.83848867  3.6784626\n",
      "   4.61299706  3.42716126 -2.4031184   2.64414374  4.24892328  3.50237445\n",
      "   0.30272332 -2.23374952 -4.50136624  4.26101034]\n",
      " [-2.15546389 -2.31556762 -2.14460073  1.47295189 -3.01040137  3.90491364\n",
      "  -1.97973709  3.02891999  2.31488298  0.35380983 -0.33495767 -4.11142184\n",
      "   1.21906404 -0.20424444 -0.31128274 -3.04897768]\n",
      " [ 1.30898943  4.20720354 -3.19613835  4.11446983 -2.23005841 -4.02910586\n",
      "  -1.26069748  2.09545163  2.6885244  -1.75948825  1.56359619 -2.44661985\n",
      "  -2.77951319 -0.70667991  0.54765451  1.54466179]]\n",
      "(16, 10)\n",
      "[[ 0.42513209  0.79129046  3.86011486 -2.11141676 -2.08337311 -0.38152384\n",
      "  -0.43455812  4.06589004  0.62552887  1.73142998]\n",
      " [ 2.93519931 -2.77541256 -3.80925897  3.78254168  4.72412973  1.54056384\n",
      "   2.54169404 -1.54633982 -4.8055442  -1.19168303]\n",
      " [ 1.62773638 -0.94287089 -0.29447996 -1.70837848 -4.05250934 -0.86071857\n",
      "  -3.3600002   2.73572421 -0.60115295  0.65724397]\n",
      " [ 2.44513985  4.6653414  -4.29565136  2.1428023   1.06982526 -0.13105619\n",
      "  -3.31933716  1.61437964 -1.76957667 -1.06732106]\n",
      " [ 1.90871648 -0.69677408 -0.52287177  3.05568782  1.45706042 -0.06861794\n",
      "   0.67804808  1.02953514  0.47014879  2.37598287]\n",
      " [ 0.7615756  -0.47702408  0.56936997  2.03699293  1.42306797  1.22250555\n",
      "  -4.39277523 -2.55223673  3.0712535  -0.21646618]\n",
      " [-1.96707085 -4.51872789  1.46234354  0.66709568 -3.96657131  2.97177936\n",
      "   3.95405297  4.17380891 -3.11308949 -0.98290016]\n",
      " [-4.42033272 -1.57176794  0.51501279 -3.93365942  2.36324638 -2.13549976\n",
      "   1.5896797  -3.05869417  3.22634444  4.29682756]\n",
      " [-2.47295549 -4.21676686 -4.9386875  -0.69767192  1.88986053  3.72063821\n",
      "  -3.50564333  0.01804643 -0.49443584 -1.4470033 ]\n",
      " [-0.21242803 -1.36983405 -0.18375086 -2.88653317  1.27319177 -1.81886131\n",
      "   4.15196325 -2.54424693 -2.01051434  3.08132148]\n",
      " [-2.58361206  1.95315788 -0.78307559  4.12235264 -0.68360688 -1.71828484\n",
      "  -4.11800418  0.59434951 -0.73547512 -0.12783446]\n",
      " [-3.00640353  1.45193947  2.26519195  1.34930861  4.20738301 -3.31745524\n",
      "  -2.79531213  1.4726877  -4.86706425 -3.00854594]\n",
      " [-4.75000659  2.44494281 -1.53612543 -2.01243197  1.35864147  4.7701791\n",
      "  -4.04244615 -2.98586947  3.49996067  2.78142444]\n",
      " [ 1.08107186  0.20456062  2.84320718 -2.38617362 -1.48996784 -2.17195429\n",
      "  -4.01811322 -4.5642696  -3.61493963  0.72233561]\n",
      " [ 1.95346535  4.16539986  4.35979864  3.61969216 -1.43372736 -0.3376082\n",
      "  -0.6869204  -0.27307605  0.96823788  4.2582295 ]\n",
      " [-4.84110971  4.66902679 -3.54070757 -2.51572245 -4.31685183  2.05513002\n",
      "  -4.9180818   0.28222284  1.50280281  4.00165792]]\n",
      "(16,)\n",
      "(16,)\n",
      "(10,)\n",
      "[ 9.04276194  8.1659881  -6.62489348 -8.56971278 -7.62476699 -1.49152536\n",
      " -9.28330866 -8.36332864 -3.82844815  4.84887575 -8.50083543 -0.76704952\n",
      " -7.28888425  0.5568511   1.71062277 -9.76860402]\n",
      "[ 9.68368076  0.97731253 -4.17656381  2.50668306 -5.72378815 -5.56333835\n",
      "  3.40271622 -2.27767455  1.63210826 -8.41893724 -2.95893346  4.51775206\n",
      "  8.4029181   4.532408    6.87003891 -1.43908972]\n",
      "[-4.53404098  4.04244779 -2.94067882 -1.99988672  4.73245994 -6.65568867\n",
      " -1.53166373 -5.65366154 -9.25615983 -0.79742987]\n",
      "13002\n"
     ]
    }
   ],
   "source": [
    "n1Size = 784\n",
    "n2Size = 16\n",
    "n3Size = 16\n",
    "n4Size = 10\n",
    "\n",
    "\n",
    "l1Weights = np.array([])\n",
    "\n",
    "for i in range(n1Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n2Size):\n",
    "        # temp is an array of weights from ith neuron to all 16 neurons in the second layer\n",
    "        temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "    if l1Weights.size == 0:\n",
    "        l1Weights = np.array([temp])\n",
    "    else:\n",
    "        l1Weights = np.append(l1Weights, [temp], axis=0)    \n",
    "\n",
    "print(l1Weights.shape)\n",
    "print(l1Weights)\n",
    "\n",
    "\n",
    "l2Weights = np.array([])\n",
    "\n",
    "for i in range(n2Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n3Size):\n",
    "        temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "    if l2Weights.size == 0:\n",
    "        l2Weights = np.array([temp])\n",
    "    else:\n",
    "        l2Weights = np.append(l2Weights, [temp], axis=0)     \n",
    "\n",
    "print(l2Weights.shape)\n",
    "print(l2Weights)\n",
    "\n",
    "\n",
    "l3Weights = np.array([])\n",
    "\n",
    "for i in range(n3Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n4Size):\n",
    "        temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "    if l3Weights.size == 0:\n",
    "        l3Weights = np.array([temp])\n",
    "    else:\n",
    "        l3Weights = np.append(l3Weights, [temp], axis=0)  \n",
    "\n",
    "        \n",
    "print(l3Weights.shape)\n",
    "print(l3Weights)\n",
    "\n",
    "\n",
    "l2Biases = np.array([])\n",
    "l3Biases = np.array([])\n",
    "l4Biases = np.array([])\n",
    "\n",
    "for i in range(16):\n",
    "    l2Biases = np.append(l2Biases, np.random.uniform(-10, 10))\n",
    "    l3Biases = np.append(l3Biases, np.random.uniform(-10, 10))\n",
    "    if i < 10:\n",
    "        l4Biases = np.append(l4Biases, np.random.uniform(-10, 10))\n",
    "\n",
    "print(l2Biases.shape)\n",
    "print(l3Biases.shape)        \n",
    "print(l4Biases.shape) \n",
    "\n",
    "print(l2Biases)\n",
    "print(l3Biases)        \n",
    "print(l4Biases)   \n",
    "\n",
    "        \n",
    "        \n",
    "print(l1Weights.size + l2Weights.size + l3Weights.size + l2Biases.size + l3Biases.size + l4Biases.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4a66fa-b758-43ac-b7b7-b8311dd6ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the network fully set up.\n",
    "# We have 4 layers of neurons\n",
    "# 13002 parameters (weights and biases) with the weights being randomized between [-5, 5] and the biases randomized between [-10, 10]\n",
    "# The 1st layer already has the values of the 1st image and the 2-4th layers all contain neurons initialized at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4a4c38-f12f-4d74-9543-025faf32ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the sigmoid function as our activation function\n",
    "def sigmoid(x):\n",
    "\n",
    "    x = np.float128(x)\n",
    "    \n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "    \n",
    "\n",
    "class Network:\n",
    "    \n",
    "    def setWeights(self, w1, w2, w3):\n",
    "        self.w1 = np.copy(w1)\n",
    "        self.w2 = np.copy(w2)\n",
    "        self.w3 = np.copy(w3)\n",
    "        \n",
    "    def setBiases(self, b2, b3, b4):\n",
    "        self.b2 = np.copy(b2)\n",
    "        self.b3 = np.copy(b3)\n",
    "        self.b4 = np.copy(b4)\n",
    "\n",
    "    def setNeurons(self, n1, n2, n3, n4):\n",
    "        self.n1 = np.copy(n1)\n",
    "        self.n2 = np.copy(n2)\n",
    "        self.n3 = np.copy(n3)\n",
    "        self.n4 = np.copy(n4)\n",
    "\n",
    "    # loads an image into the 1st layer\n",
    "    def initImage(self, data, index):\n",
    "        \n",
    "        self.n1 = np.array([])\n",
    "\n",
    "        # print(data[index].shape[0])\n",
    "        # print(data[index].shape[1])\n",
    "\n",
    "        \n",
    "        for i in range(data[index].shape[0]):\n",
    "            for j in range(data[index].shape[1]):\n",
    "                self.n1 = np.append(self.n1, Neuron(data[index][i][j]))\n",
    "\n",
    "    def runImage(self):\n",
    "        \n",
    "        for i in range(self.n2.size): # Per 2nd layer neuron\n",
    "            _sum = 0.0\n",
    "            for j in range(self.n1.size): # Per 1st layer neuron\n",
    "                _sum += self.n1[j].getActivation() * self.w1[j][i]\n",
    "            z = _sum + self.b2[i]\n",
    "            a = sigmoid(z)\n",
    "            self.n2[i].setActivation(a)\n",
    "            self.n2[i].z = z\n",
    "\n",
    "        for i in range(self.n3.size): # Per 3rd layer neuron\n",
    "            _sum = 0.0\n",
    "            for j in range(self.n2.size): # Per 2nd layer neuron\n",
    "                _sum += self.n2[j].getActivation() * self.w2[j][i]\n",
    "            z = _sum + self.b3[i]\n",
    "            a = sigmoid(z)\n",
    "            self.n3[i].setActivation(a)\n",
    "            self.n3[i].z = z\n",
    "\n",
    "        for i in range(self.n4.size): # Per 4th layer neuron\n",
    "            _sum = 0.0\n",
    "            for j in range(self.n3.size): # Per 3rd layer neuron\n",
    "                _sum += self.n3[j].getActivation() * self.w3[j][i]\n",
    "            z = _sum + self.b4[i]\n",
    "            a = sigmoid(z)\n",
    "            self.n4[i].setActivation(a)\n",
    "            self.n4[i].z = z\n",
    "\n",
    "    def calcLoss(self, target):\n",
    "        loss = 0.0\n",
    "        for i in range(self.n4.size):\n",
    "            if i == target:\n",
    "                loss += (self.n4[i].getActivation() - 1.0) ** 2.0\n",
    "            else:\n",
    "                loss += self.n4[i].getActivation() ** 2.0\n",
    "        return loss\n",
    "    \n",
    "    def isCorrect(self, target):\n",
    "        return target == getMaxNumber(self.n4)\n",
    "            \n",
    "    \n",
    "    # Backprop\n",
    "    \n",
    "    def backProp_n4(self, target):\n",
    "        \n",
    "        \n",
    "        for i in range(self.n3.size):\n",
    "            for j in range(self.n4.size):\n",
    "                if (j == target):\n",
    "                    self.w3_mod[i][j] += self.n3[i].getActivation() * sigmoid_prime(self.n4[j].z) * 2.0 * (self.n4[j].getActivation() - 1.0)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    self.w3_mod[i][j] += self.n3[i].getActivation() * sigmoid_prime(self.n4[j].z) * 2.0 * (self.n4[j].getActivation())\n",
    "            \n",
    "            \n",
    "        for i in range(self.n4.size):\n",
    "            if i == target:\n",
    "                self.b4_mod[i] += sigmoid_prime(self.n4[i].z) * 2.0 * (self.n4[i].getActivation() - 1.0)\n",
    "            else:\n",
    "                self.b4_mod[i] += sigmoid_prime(self.n4[i].z) * 2.0 * (self.n4[i].getActivation())\n",
    "    \n",
    "    def backProp_n3(self):\n",
    "        \n",
    "#         print(\"arrivedn3\")\n",
    "    \n",
    "        \n",
    "        \n",
    "        for i in range(self.n2.size):        \n",
    "            \n",
    "            for j in range(self.n3.size):\n",
    "                temp1 = self.n2[i].getActivation() * sigmoid_prime(self.n3[j].z)\n",
    "                temp2 = 0.0\n",
    "                for k in range(self.n4.size):\n",
    "                    temp2 += self.w3_mod[j][k]\n",
    "                \n",
    "                self.w2_mod[i][j] += temp1 * temp2\n",
    "        \n",
    "        for i in range(self.b3.size):\n",
    "            \n",
    "            temp1 = sigmoid_prime(self.n3[i].z)\n",
    "            temp2 = 0.0\n",
    "            for j in range(self.b4.size):\n",
    "                temp2 += self.b4_mod[j]\n",
    "            self.b3_mod[i] += temp1 * temp2\n",
    "            \n",
    "        \n",
    "    \n",
    "    def backProp_n2(self):\n",
    "        \n",
    "        for i in range(self.n1.size):  \n",
    "            for j in range(self.n2.size):\n",
    "                temp1 = self.n1[i].getActivation() * sigmoid_prime(self.n2[j].z)\n",
    "                temp2 = 0.0\n",
    "                \n",
    "                for k in range(self.n3.size):\n",
    "                    temp2 += self.w2_mod[j][k]\n",
    "                \n",
    "                self.w1_mod[i][j] += temp1 * temp2\n",
    "        \n",
    "        for i in range(self.b2.size):\n",
    "            \n",
    "            temp1 = sigmoid_prime(self.n2[i].z)\n",
    "            temp2 = 0.0\n",
    "            for j in range(self.b3.size):\n",
    "                temp2 += self.b3_mod[j]\n",
    "            self.b2_mod[i] += temp1 * temp2\n",
    "        \n",
    "    def backProp(self, target):\n",
    "        self.backProp_n4(target)\n",
    "        self.backProp_n3()\n",
    "        self.backProp_n2()\n",
    "    \n",
    "    def runBatch(self, data, labels, startIdx = 0, batchSize=1000):\n",
    "        \n",
    "        self.w3_mod = np.copy(self.w3)\n",
    "        self.w3_mod.fill(0.0)\n",
    "        \n",
    "        self.b4_mod = np.copy(self.b4)\n",
    "        self.b4_mod.fill(0.0)\n",
    "        \n",
    "        \n",
    "        self.w2_mod = np.copy(self.w2)\n",
    "        self.w2_mod.fill(0.0)\n",
    "        \n",
    "        self.b3_mod = np.copy(self.b3)\n",
    "        self.b3_mod.fill(0.0)\n",
    "        \n",
    "        \n",
    "        self.w1_mod = np.copy(self.w1)\n",
    "        self.w1_mod.fill(0.0)\n",
    "        \n",
    "        self.b2_mod = np.copy(self.b2)\n",
    "        self.b2_mod.fill(0.0)\n",
    "        \n",
    "        loss = 0.0\n",
    "        counter = 0\n",
    "        for i in range(startIdx, startIdx + batchSize):\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "                \n",
    "            self.initImage(data, i)\n",
    "            self.runImage()\n",
    "            loss += self.calcLoss(labels[i])\n",
    "            if self.isCorrect(labels[i]):\n",
    "                counter += 1\n",
    "            self.backProp(labels[i])\n",
    "\n",
    "\n",
    "        # ASSUMING BATCH SIZE == 1000\n",
    "        loss /= 1000.0\n",
    "        print(loss)\n",
    "        print(counter / batchSize)\n",
    "\n",
    "        # ASSUMING BATCH SIZE == 1000\n",
    "        \n",
    "        # May be not needed\n",
    "        # self.w3_mod = np.divide(self.w3_mod, 1000.0)\n",
    "        # self.w2_mod = np.divide(self.w2_mod, 1000.0)\n",
    "        # self.w1_mod = np.divide(self.w1_mod, 1000.0)\n",
    "        # self.b4_mod = np.divide(self.b4_mod, 1000.0)\n",
    "        # self.b3_mod = np.divide(self.b3_mod, 1000.0)\n",
    "        # self.b2_mod = np.divide(self.b2_mod, 1000.0)\n",
    "        \n",
    "        for i in range(self.n3.size):\n",
    "            for j in range(self.n4.size):\n",
    "                self.w3[i][j] -= self.w3_mod[i][j]\n",
    "        \n",
    "        for i in range(self.n2.size):\n",
    "            for j in range(self.n3.size):\n",
    "                self.w2[i][j] -= self.w2_mod[i][j]\n",
    "        \n",
    "        for i in range(self.n1.size):\n",
    "            for j in range(self.n2.size):\n",
    "                self.w1[i][j] -= self.w1_mod[i][j]\n",
    "        \n",
    "        for i in range(self.b4.size):\n",
    "            self.b4[i] -= self.b4_mod[i]\n",
    "        \n",
    "        for i in range(self.b3.size):\n",
    "            self.b3[i] -= self.b3_mod[i]\n",
    "            \n",
    "        for i in range(self.b2.size):\n",
    "            self.b2[i] -= self.b2_mod[i]\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8ca8ae6-2564-484b-9a74-c405ed8da370",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstNetwork = Network()\n",
    "firstNetwork.setWeights(l1Weights, l2Weights, l3Weights)\n",
    "firstNetwork.setBiases(l2Biases, l3Biases, l4Biases)\n",
    "firstNetwork.setNeurons(l1, l2, l3, l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a35e218c-f46d-46ad-9c4c-6f137affbefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets do a run with our loaded data\n",
    "\n",
    "# # Calculates activation of neurons in the second layer\n",
    "# for i in range(firstNetwork.n2.size): # Per 2nd layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n1.size): # Per 1st layer neuron\n",
    "#         sum += firstNetwork.n1[j].getActivation() * firstNetwork.w1[j][i]\n",
    "#     z = sum + firstNetwork.b2[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n2[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73c447b4-fc4d-4a0f-a3c0-7b316d262a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(16):\n",
    "#     print(firstNetwork.n2[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f300331a-aee6-4532-be74-11fde8349732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3rd layer\n",
    "\n",
    "# for i in range(firstNetwork.n3.size): # Per 3rd layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n2.size): # Per 2nd layer neuron\n",
    "#         sum += firstNetwork.n2[j].getActivation() * firstNetwork.w2[j][i]\n",
    "#     z = sum + firstNetwork.b3[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n3[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95369675-fe14-42b3-9003-ea04c8f1088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(16):\n",
    "#     print(firstNetwork.n3[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5563a59-9210-4f36-b950-3626615d6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #head\n",
    "\n",
    "# for i in range(firstNetwork.n4.size): # Per 4th layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n3.size): # Per 3rd layer neuron\n",
    "#         sum += firstNetwork.n3[j].getActivation() * firstNetwork.w3[j][i]\n",
    "#     z = sum + firstNetwork.b4[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n4[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33bdf44b-07f6-4f11-b782-028ae86cfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(firstNetwork.n4[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf271e11-ee5b-4fc5-944b-a9386aa46f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a8df18-9920-4e1d-b6ca-7cd6c40d77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels[0])\n",
    "# print(firstNetwork.calcLoss(5))\n",
    "# print(getMaxNumber(firstNetwork.n4))\n",
    "# print(getMax(firstNetwork.n4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c17334e-cc13-4bed-bcb0-acbb260931b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(cost) / del(weight) == a(l-1) * sig'(z) * 2(a - y)\n",
    "# del(cost) / del(bias) == sig'(z) * 2(a - y)\n",
    "\n",
    "#### BACKPROP ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa65fa2f-80f9-42a7-ac48-dcf98a9715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstNetwork.backProp_n4(5)\n",
    "# print(firstNetwork.w3_mod)\n",
    "# print(firstNetwork.b4_mod)\n",
    "\n",
    "# firstNetwork.backProp_n3()\n",
    "# print(firstNetwork.w2_mod)\n",
    "# print(firstNetwork.b3_mod)\n",
    "# firstNetwork.backProp_n2()\n",
    "# print(firstNetwork.w1_mod)\n",
    "# print(firstNetwork.b2_mod)\n",
    "\n",
    "# for i in range(784):\n",
    "#     for j in range(16):\n",
    "#         print(firstNetwork.w1_mod[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f981ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "3.8862882179404395198\n",
      "0.132\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46091/2783202751.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "0.9919379223799613571\n",
      "0.106\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "0.99252319418175771287\n",
      "0.094\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "1.4399012604695347942\n",
      "0.094\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "0.99998110427297320555\n",
      "0.089\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "0.99998076360103122184\n",
      "0.089\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "0.9999782005000482317\n",
      "0.099\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "0.99997682095350196756\n",
      "0.103\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "0.9999785803899681677\n",
      "0.093\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "0.99997697068375687913\n",
      "0.098\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "0.99997930174113343083\n",
      "0.086\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "0.9999761892937728685\n",
      "0.097\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "0.9999748717721066989\n",
      "0.1\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "0.9999727073025860908\n",
      "0.106\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m60000\u001b[39m, \u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mfirstNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting Testing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m firstNetwork\u001b[38;5;241m.\u001b[39mrunBatch(test_images, test_labels) \u001b[38;5;66;03m# TODO: Don't backpropagate on test runs\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 191\u001b[0m, in \u001b[0;36mNetwork.runBatch\u001b[0;34m(self, data, labels, startIdx, batchSize)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misCorrect(labels[i]):\n\u001b[1;32m    190\u001b[0m         counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackProp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# ASSUMING BATCH SIZE == 1000\u001b[39;00m\n\u001b[1;32m    195\u001b[0m loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000.0\u001b[39m\n",
      "Cell \u001b[0;32mIn[11], line 156\u001b[0m, in \u001b[0;36mNetwork.backProp\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackProp_n4(target)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackProp_n3()\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackProp_n2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 137\u001b[0m, in \u001b[0;36mNetwork.backProp_n2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn1\u001b[38;5;241m.\u001b[39msize):  \n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2\u001b[38;5;241m.\u001b[39msize):\n\u001b[0;32m--> 137\u001b[0m         temp1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn1[i]\u001b[38;5;241m.\u001b[39mgetActivation() \u001b[38;5;241m*\u001b[39m \u001b[43msigmoid_prime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m         temp2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn3\u001b[38;5;241m.\u001b[39msize):\n",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m, in \u001b[0;36msigmoid_prime\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid_prime\u001b[39m(x):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m sigmoid(x))\n",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(x):\n\u001b[1;32m      4\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat128(x)\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    for i in range(0, 60000, 1000):\n",
    "        firstNetwork.runBatch(train_images, train_labels, i)\n",
    "    \n",
    "print(\"Starting Testing\")\n",
    "firstNetwork.runBatch(test_images, test_labels) # TODO: Don't backpropagate on test runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000, 10000, 1000):\n",
    "    firstNetwork.runBatch(test_images, test_labels, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03292a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels[9999])\n",
    "for neuron in firstNetwork.n4:\n",
    "    print(neuron.getActivation())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84dedd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 60000, 1000):\n",
    "    firstNetwork.runBatch(train_images, train_labels, i)\n",
    "    \n",
    "print(\"Starting Testing\")\n",
    "for i in range(0, 10000, 1000):\n",
    "    firstNetwork.runBatch(test_images, test_labels, i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60859c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_neuralnet",
   "language": "python",
   "name": "mnist_neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
