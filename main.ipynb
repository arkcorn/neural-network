{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96052a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 18:05:50.913238: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 18:05:50.920878: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-06 18:05:50.942776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 18:05:50.976703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 18:05:50.986961: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 18:05:51.014682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 18:05:52.973689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1921ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads mnist data into variables\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1254718-3c5b-429f-96dd-370250e7f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264b3b4b-b73c-484b-9090-5ddd3e7044ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel values by default are [0,255] (where 0 is black and 255 is white)\n",
    "# We normalize these values for better compatibility with my model\n",
    "train_images = train_images.astype('float32')/255.0\n",
    "test_images = test_images.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f15303d4-12aa-4104-8eeb-beb1b572dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = 2\n",
    "cols = 4\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 5))\n",
    "\n",
    "# Commented code shows first 8 images (indices 0-7)\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        index = j + (cols * i)\n",
    "        axes[i, j].imshow(train_images[index], cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "\n",
    "# # Show 8 random images in the dataset\n",
    "# for i in range(rows):\n",
    "#     for j in range(cols):\n",
    "#         index = random.randint(0, train_images.shape[0] - 1)\n",
    "#         axes[i, j].imshow(train_images[index], cmap='gray')\n",
    "#         axes[i, j].axis('off')\n",
    "\n",
    "fig.suptitle(\"MNIST Dataset Sample Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8e8a3e-a415-44fe-bda6-da00a2bdb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defines the neuron class\n",
    "class Neuron:\n",
    "    def __init__(self, activation, z=0.0):\n",
    "        self.activation = activation\n",
    "        self.z = z\n",
    "\n",
    "    def setActivation(self, num):\n",
    "        self.activation = num\n",
    "\n",
    "    def getActivation(self):\n",
    "        return self.activation\n",
    "\n",
    "# Gets the max value from an array of neurons\n",
    "def getMax(l):\n",
    "    _max = l[0].getActivation()\n",
    "    for i in range(1, l.size):\n",
    "        if l[i].getActivation() > _max:\n",
    "            _max = l[i].getActivation()\n",
    "    return _max    \n",
    "\n",
    "# Returns the number (index) which has the highest activation\n",
    "def getMaxNumber(l):\n",
    "    max_act = l[0].getActivation()\n",
    "    max_idx = 0\n",
    "    for i in range(1, l.size):\n",
    "        if l[i].getActivation() > max_act:\n",
    "            max_act = l[i].getActivation()\n",
    "            max_idx = i\n",
    "            \n",
    "    return max_idx\n",
    "\n",
    "# Takes an image (index) and changes the 1st layer of neuron accordingly\n",
    "def fillFirstLayer(l, data, index):\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            l = np.append(l, Neuron(data[index][i][j]))\n",
    "            \n",
    "    return l\n",
    "\n",
    "# Used to initialize layers 2-4\n",
    "def fillLayerWithZeroNeurons(l, num):\n",
    "    for i in range(num):\n",
    "        l = np.append(l, Neuron(0))\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e7d4ed-4958-4416-92e9-e169474d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer 1 will be composed of the pixel values of the image inputted\n",
    "l1 = np.array([])\n",
    "\n",
    "# layers 2-3 will be the 'hidden layers' or 'black box' of the network\n",
    "l2 = np.array([])\n",
    "l3 = np.array([])\n",
    "\n",
    "# layer 4 will be the output layer or the head\n",
    "l4 = np.array([])\n",
    "\n",
    "# initialize the layers here\n",
    "l1 = fillFirstLayer(l1, train_images, 0)\n",
    "l2 = fillLayerWithZeroNeurons(l2, 16)\n",
    "l3 = fillLayerWithZeroNeurons(l3, 16)\n",
    "l4 = fillLayerWithZeroNeurons(l4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7f9c6a-bf28-4140-82e4-c6289f84dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Here we are assigning random weights and biases\n",
    "# After this chunk runs all 13,002 parameters have a value\n",
    "# Weights are between -5 and 5 and biases are between -10 and 10\n",
    "# \"\"\"\n",
    "\n",
    "# l1Weights = np.array([])\n",
    "\n",
    "# for i in range(l1.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l2.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l1Weights.size == 0:\n",
    "#         l1Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l1Weights = np.append(l1Weights, [temp], axis=0)    \n",
    "\n",
    "# print(l1Weights.shape)\n",
    "\n",
    "# l2Weights = np.array([])\n",
    "\n",
    "# for i in range(l2.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l3.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l2Weights.size == 0:\n",
    "#         l2Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l2Weights = np.append(l2Weights, [temp], axis=0)     \n",
    "\n",
    "# print(l2Weights.shape)\n",
    "\n",
    "# l3Weights = np.array([])\n",
    "\n",
    "# for i in range(l3.size):\n",
    "#     temp = np.array([])\n",
    "#     for j in range(l4.size):\n",
    "#         temp = np.append(temp, np.random.uniform(-5, 5))\n",
    "#     if l3Weights.size == 0:\n",
    "#         l3Weights = np.array([temp])\n",
    "#     else:\n",
    "#         l3Weights = np.append(l3Weights, [temp], axis=0)  \n",
    "\n",
    "# print(l3Weights.shape)\n",
    "\n",
    "# l2Biases = np.array([])\n",
    "# l3Biases = np.array([])\n",
    "# l4Biases = np.array([])\n",
    "\n",
    "# for i in range(16):\n",
    "#     l2Biases = np.append(l2Biases, np.random.uniform(-10, 10))\n",
    "#     l3Biases = np.append(l3Biases, np.random.uniform(-10, 10))\n",
    "#     if i < 10:\n",
    "#         l4Biases = np.append(l4Biases, np.random.uniform(-10, 10))\n",
    "\n",
    "# print(l1Weights.size + l2Weights.size + l3Weights.size + l2Biases.size + l3Biases.size + l4Biases.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd05737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 16)\n",
      "[[-2.71691537e-01  1.01282807e+00 -3.09838433e-01 ...  2.07836415e+00\n",
      "  -2.98615506e-02 -1.90724314e+00]\n",
      " [-2.10701404e+00 -1.50804174e+00 -7.13940295e-02 ...  1.17691972e+00\n",
      "  -7.62364738e-01  5.68919131e-01]\n",
      " [-1.02113695e+00 -8.91348528e-01  7.51271048e-01 ... -3.16684215e-01\n",
      "  -1.82617368e+00  6.64460558e-01]\n",
      " ...\n",
      " [-3.13982428e-01  1.37085368e+00 -9.07774265e-01 ...  2.20220722e-01\n",
      "  -1.80563240e+00  2.14234003e-01]\n",
      " [-1.33194650e-01 -5.98938583e-01 -1.17033334e-01 ... -3.33885484e-01\n",
      "  -1.15609120e+00  1.14148376e-03]\n",
      " [-5.60161578e-01 -1.87439247e-01  1.66999003e+00 ...  1.14938942e+00\n",
      "  -1.27593880e+00 -5.66340032e-02]]\n",
      "(16, 16)\n",
      "[[-0.0439526   0.08275434 -1.20302788  2.31469206  0.53918257 -0.63937511\n",
      "  -0.32936681  1.50108668  0.57545101 -1.52993875  1.51339628 -0.90734513\n",
      "   0.46028295  1.30602574 -0.68497113  0.25151756]\n",
      " [-0.1538541   0.29421603  0.25752993 -0.06801901 -0.09958796 -0.30312212\n",
      "  -0.15164956  2.00378955 -1.27146232  0.20551219  1.13757136 -0.67119375\n",
      "   0.33046253 -0.34831244 -0.06475663 -0.04691297]\n",
      " [-0.68391455 -0.29287355  0.27057625  0.72822475  0.387262    0.70296533\n",
      "   0.40995839 -0.94695083 -0.60492143  0.15982658  1.3691299  -0.12912999\n",
      "   1.26362842 -0.03835264  1.40353796 -2.3693408 ]\n",
      " [ 0.74569631 -0.06095064 -0.42612846  0.92076515 -2.20215171  0.40976334\n",
      "  -0.89176071 -0.59289721  1.8129722   0.36760921  1.69089269  0.14554817\n",
      "   0.50166789 -0.08272529 -0.24175919  0.25586382]\n",
      " [ 0.30704419 -0.41848863 -0.124094    0.49498692 -0.76175772 -0.95534288\n",
      "  -0.25259838  0.51221795  0.22789902  1.19319469 -1.14699504 -0.50486157\n",
      "   0.08506746  0.72725217 -1.22476133 -1.04349608]\n",
      " [-1.88190365  0.62893965 -1.14169728 -1.1023968  -0.62288958  1.02518293\n",
      "   0.7090836  -1.29955574  0.77697577  1.60826931 -0.04439132 -1.11542509\n",
      "   0.90565378  0.32269161  0.79890869 -0.03977106]\n",
      " [-1.63727651 -0.19622556 -0.98177026  0.39057133  0.29732299 -0.07132411\n",
      "   1.06056997  1.2323589   0.29454263 -1.15884094  1.1718016  -1.1512007\n",
      "  -0.00473498  2.17646583 -0.2939664  -1.17209336]\n",
      " [ 1.58688683  1.78740152 -0.39002073 -0.24829704 -0.91056232 -0.219908\n",
      "   0.85842799 -0.89232286 -0.92532913  1.39084209  1.26392583 -1.01592297\n",
      "  -0.73108103 -0.85347088  1.98038839 -1.29960536]\n",
      " [ 0.14921416  1.60389056  0.44943949 -0.90560522 -0.90028996 -0.96117397\n",
      "   0.15797002  1.46965936 -0.04369118 -0.8785939  -1.27840417  0.12151361\n",
      "   1.49568258  1.10232953  1.55160281  0.44413228]\n",
      " [-0.84389454 -0.63056619  0.68832036 -0.70638633  0.82121317 -0.3162879\n",
      "   0.67791037 -0.51740416  0.03962059  0.31412802 -0.55751547  0.27994288\n",
      "   0.14947147 -0.78652635 -0.31019039 -0.5237556 ]\n",
      " [ 0.82216148  0.14888564  1.32686706  0.30931672  0.14414764 -1.78695803\n",
      "   0.0411076  -0.68065737 -2.10619962  0.56459467  2.21052469  0.03128996\n",
      "   0.80067736 -1.0976359  -0.32675449 -1.27544956]\n",
      " [-0.17095694  0.51118739  2.81104782 -0.53600032  0.36816036 -0.7390012\n",
      "  -0.03407412  1.24643316 -0.96507333  0.1544784   1.21582069  0.44016269\n",
      "   0.95076982 -0.27821772  1.44691076 -0.23618074]\n",
      " [ 0.27124116  0.30174566 -2.3043091  -0.99069159  1.77482169  1.7704004\n",
      "  -0.02057226 -1.39028857  1.83265077  0.07187093 -1.00028244 -0.67264863\n",
      "   0.2848837  -0.19020319 -0.95119901  0.69209514]\n",
      " [-0.15072085  0.8779611   2.4176398   0.66503682  0.97959756  0.33764668\n",
      "  -0.64210674 -0.26754856  0.31948352 -0.34179163 -0.16637317  0.88014364\n",
      "   0.13874882 -0.58246861 -0.2132881   1.40773988]\n",
      " [ 0.42443643 -0.98194214  0.27060111 -0.24304777  0.85542625  0.46236068\n",
      "   0.44330306 -0.32074329 -0.45065022 -0.41497479  1.14807243  0.13307456\n",
      "  -0.26877966 -2.37101391 -1.5175793   0.06892931]\n",
      " [-0.21473779 -0.22277841  0.4484052   0.8065381  -0.53442627  1.84732523\n",
      "   0.92577367  1.11832262  0.09775096 -1.09838741  0.63193094 -0.38187204\n",
      "  -0.76423471  0.89946676 -1.57165685 -1.05491485]]\n",
      "(16, 10)\n",
      "[[-0.26622649  0.05287657  0.02679005  0.7660871   0.19109813  0.53107247\n",
      "   0.10355651  1.43455064  0.99293567  0.76044825]\n",
      " [-0.26381641  1.88036865 -0.46439086 -0.63454576  0.35667908  0.07787291\n",
      "   0.15695532  0.17745068 -1.94404201  0.6182585 ]\n",
      " [ 0.65510802 -0.6258327   1.14931142  0.87168119  1.26555007 -0.17477457\n",
      "  -0.07315589 -0.27373636 -0.44048266  0.17492387]\n",
      " [ 0.12279597 -0.8916206  -1.87576868 -0.68423494 -1.10569917 -0.94332984\n",
      "  -1.94763217  1.76856281  0.35522863  1.48837868]\n",
      " [ 0.22618502 -0.36109423  0.34842688 -0.91002204 -1.15883381 -0.0383678\n",
      "  -0.28402675  1.63376429 -1.81968223  0.45021712]\n",
      " [-0.41033998  1.01646307  1.18117197  0.07309521  0.18910614  1.42900502\n",
      "  -0.97831624 -0.71343131  0.59965443  0.24581   ]\n",
      " [ 0.115012   -1.32513623  0.24879723  1.30534295  0.49623981  0.13199895\n",
      "   0.41219266 -1.07576571 -0.20995741 -0.9139908 ]\n",
      " [-0.99506001  0.71655283  0.90123731 -0.58225498 -1.57016449  0.85055273\n",
      "  -1.44793496 -1.41524966  0.31920378  0.69969286]\n",
      " [ 0.84869855  1.58090195  0.6540207  -1.32062345 -0.29337629 -0.6080287\n",
      "  -0.17562386 -0.13777286 -0.19081881 -1.88167072]\n",
      " [ 0.77994446 -0.05236911  0.58774112 -1.73530635 -1.32257594  0.16823687\n",
      "  -1.91041944  1.33199416 -1.8836729   1.06510894]\n",
      " [ 0.3395975   0.42005172  0.68137659  0.75383975 -0.36629013 -0.18498977\n",
      "  -0.33174946 -0.95339857  0.10689845  0.33891783]\n",
      " [ 0.52735811 -0.53417614  0.49033107  0.23565288  0.51912199 -1.23004468\n",
      "   1.33082153  0.21018178  0.60589681 -0.08660825]\n",
      " [ 0.7370778  -1.1249441   0.28722781  0.31649571  1.73615471  1.96634475\n",
      "  -0.47982177 -0.21289501 -0.56156222 -0.52699542]\n",
      " [ 0.83399529  0.88623867 -1.12606299  0.28396859 -0.30986419 -0.70114189\n",
      "   0.47431685 -0.14618412 -2.65349856  1.03560838]\n",
      " [-0.172219    1.54770118  0.57124386 -1.35587264 -0.27175987  0.23965244\n",
      "  -1.67381876  0.54886404  0.35873019  1.62969015]\n",
      " [ 0.33237995  0.05201407  0.95560507  0.32372569  0.2806691  -0.17446863\n",
      "   1.25100247  0.52285056 -0.88955429 -1.23756447]]\n",
      "(16,)\n",
      "(16,)\n",
      "(10,)\n",
      "[ 0.04472341  1.62601615 -0.69078563  0.80232484 -1.42029707  0.70869404\n",
      " -0.95510734  1.71434819  1.01992648  0.6871725  -1.97608288  1.08892885\n",
      " -2.12458966  0.40821946 -1.1347703   0.70280619]\n",
      "[ 0.84782779 -0.40531157 -0.75792411 -1.04036863 -0.28030071  0.10555645\n",
      "  0.89439755  0.21525249 -0.58372028  0.75483297  0.2080397  -0.56599778\n",
      " -0.30643203 -0.51911716 -0.00751585 -0.28281617]\n",
      "[-0.1926083   0.95024583  0.82714996 -1.31121447  1.41948732 -0.05290919\n",
      " -0.1609393   0.57047821  1.360157   -1.04049163]\n",
      "13002\n"
     ]
    }
   ],
   "source": [
    "n1Size = 784\n",
    "n2Size = 16\n",
    "n3Size = 16\n",
    "n4Size = 10\n",
    "\n",
    "\n",
    "l1Weights = np.array([])\n",
    "\n",
    "for i in range(n1Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n2Size):\n",
    "        # temp is an array of weights from ith neuron to all 16 neurons in the second layer\n",
    "        temp = np.append(temp, np.random.normal(loc=0, scale=1))\n",
    "    if l1Weights.size == 0:\n",
    "        l1Weights = np.array([temp])\n",
    "    else:\n",
    "        l1Weights = np.append(l1Weights, [temp], axis=0)    \n",
    "\n",
    "print(l1Weights.shape)\n",
    "print(l1Weights)\n",
    "\n",
    "\n",
    "l2Weights = np.array([])\n",
    "\n",
    "for i in range(n2Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n3Size):\n",
    "        temp = np.append(temp, np.random.normal(loc=0, scale=1))\n",
    "    if l2Weights.size == 0:\n",
    "        l2Weights = np.array([temp])\n",
    "    else:\n",
    "        l2Weights = np.append(l2Weights, [temp], axis=0)     \n",
    "\n",
    "print(l2Weights.shape)\n",
    "print(l2Weights)\n",
    "\n",
    "\n",
    "l3Weights = np.array([])\n",
    "\n",
    "for i in range(n3Size):\n",
    "    temp = np.array([])\n",
    "    for j in range(n4Size):\n",
    "        temp = np.append(temp, np.random.normal(loc=0, scale=1))\n",
    "    if l3Weights.size == 0:\n",
    "        l3Weights = np.array([temp])\n",
    "    else:\n",
    "        l3Weights = np.append(l3Weights, [temp], axis=0)  \n",
    "\n",
    "        \n",
    "print(l3Weights.shape)\n",
    "print(l3Weights)\n",
    "\n",
    "\n",
    "l2Biases = np.array([])\n",
    "l3Biases = np.array([])\n",
    "l4Biases = np.array([])\n",
    "\n",
    "for i in range(16):\n",
    "    l2Biases = np.append(l2Biases, np.random.normal(loc=0, scale=1))\n",
    "    l3Biases = np.append(l3Biases, np.random.normal(loc=0, scale=1))\n",
    "    if i < 10:\n",
    "        l4Biases = np.append(l4Biases, np.random.normal(loc=0, scale=1))\n",
    "\n",
    "print(l2Biases.shape)\n",
    "print(l3Biases.shape)        \n",
    "print(l4Biases.shape) \n",
    "\n",
    "print(l2Biases)\n",
    "print(l3Biases)        \n",
    "print(l4Biases)   \n",
    "\n",
    "        \n",
    "        \n",
    "print(l1Weights.size + l2Weights.size + l3Weights.size + l2Biases.size + l3Biases.size + l4Biases.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4a66fa-b758-43ac-b7b7-b8311dd6ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the network fully set up.\n",
    "# We have 4 layers of neurons\n",
    "# 13002 parameters (weights and biases) with the weights being randomized between [-5, 5] and the biases randomized between [-10, 10]\n",
    "# The 1st layer already has the values of the 1st image and the 2-4th layers all contain neurons initialized at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a4a4c38-f12f-4d74-9543-025faf32ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We are using the sigmoid function as our activation function\n",
    "# def sigmoid(x):\n",
    "\n",
    "#     x = np.float128(x)\n",
    "    \n",
    "#     return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# def sigmoid_prime(x):\n",
    "    \n",
    "#     return expit(x) * (1.0 - expit(x))\n",
    "    \n",
    "\n",
    "# class Network:\n",
    "    \n",
    "#     def setWeights(self, w1, w2, w3):\n",
    "#         self.w1 = np.copy(w1)\n",
    "#         self.w2 = np.copy(w2)\n",
    "#         self.w3 = np.copy(w3)\n",
    "        \n",
    "#     def setBiases(self, b2, b3, b4):\n",
    "#         self.b2 = np.copy(b2)\n",
    "#         self.b3 = np.copy(b3)\n",
    "#         self.b4 = np.copy(b4)\n",
    "\n",
    "#     def setNeurons(self, n1, n2, n3, n4):\n",
    "#         self.n1 = np.copy(n1)\n",
    "#         self.n2 = np.copy(n2)\n",
    "#         self.n3 = np.copy(n3)\n",
    "#         self.n4 = np.copy(n4)\n",
    "\n",
    "        \n",
    "    \n",
    "#     # loads an image into the 1st layer\n",
    "#     def initImage(self, data, index):\n",
    "        \n",
    "#         self.n1 = np.array([])\n",
    "\n",
    "#         # print(data[index].shape[0])\n",
    "#         # print(data[index].shape[1])\n",
    "\n",
    "        \n",
    "#         for i in range(data[index].shape[0]):\n",
    "#             for j in range(data[index].shape[1]):\n",
    "#                 self.n1 = np.append(self.n1, Neuron(data[index][i][j]))\n",
    "\n",
    "#     def runImage(self):\n",
    "\n",
    "        \n",
    "        \n",
    "#         for i in range(self.n2.size): # Per 2nd layer neuron\n",
    "#             _sum = 0.0\n",
    "#             for j in range(self.n1.size): # Per 1st layer neuron\n",
    "#                 _sum += self.n1[j].getActivation() * self.w1[j][i]\n",
    "#             z = _sum + self.b2[i]\n",
    "#             a = expit(z)\n",
    "#             self.n2[i].setActivation(a)\n",
    "#             self.n2[i].z = z\n",
    "\n",
    "#         for i in range(self.n3.size): # Per 3rd layer neuron\n",
    "#             _sum = 0.0\n",
    "#             for j in range(self.n2.size): # Per 2nd layer neuron\n",
    "#                 _sum += self.n2[j].getActivation() * self.w2[j][i]\n",
    "#             z = _sum + self.b3[i]\n",
    "#             a = expit(z)\n",
    "#             self.n3[i].setActivation(a)\n",
    "#             self.n3[i].z = z\n",
    "\n",
    "#         for i in range(self.n4.size): # Per 4th layer neuron\n",
    "#             _sum = 0.0\n",
    "#             for j in range(self.n3.size): # Per 3rd layer neuron\n",
    "#                 _sum += self.n3[j].getActivation() * self.w3[j][i]\n",
    "#             z = _sum + self.b4[i]\n",
    "#             a = expit(z)\n",
    "#             self.n4[i].setActivation(a)\n",
    "#             self.n4[i].z = z\n",
    "\n",
    "#     def calcLoss(self, target):\n",
    "#         loss = 0.0\n",
    "#         for i in range(self.n4.size):\n",
    "#             if i == target:\n",
    "#                 loss += (self.n4[i].getActivation() - 1.0) ** 2.0\n",
    "#             else:\n",
    "#                 loss += self.n4[i].getActivation() ** 2.0\n",
    "#         return loss\n",
    "    \n",
    "#     def isCorrect(self, target):\n",
    "#         return target == getMaxNumber(self.n4)\n",
    "            \n",
    "    \n",
    "#     # Backprop\n",
    "    \n",
    "#     def backProp_n4(self, target):\n",
    "#         y = 0\n",
    "        \n",
    "        \n",
    "#         for i in range(self.n3.size):\n",
    "#             for j in range(self.n4.size):\n",
    "#                 if (j == target):\n",
    "#                     self.w3_mod[i][j] += self.n3[i].getActivation() * sigmoid_prime(self.n4[j].z) * 2.0 * (self.n4[j].getActivation() - 1.0)\n",
    "                    \n",
    "                    \n",
    "#                 else:\n",
    "#                     self.w3_mod[i][j] += self.n3[i].getActivation() * sigmoid_prime(self.n4[j].z) * 2.0 * (self.n4[j].getActivation())\n",
    "            \n",
    "            \n",
    "#         for i in range(self.n4.size):\n",
    "#             if i == target:\n",
    "#                 self.b4_mod[i] += sigmoid_prime(self.n4[i].z) * 2.0 * (self.n4[i].getActivation() - 1.0)\n",
    "#             else:\n",
    "#                 self.b4_mod[i] += sigmoid_prime(self.n4[i].z) * 2.0 * (self.n4[i].getActivation())\n",
    "    \n",
    "#     def backProp_n3(self, target):\n",
    "#         y = 0\n",
    "#         for i in range(self.n2.size):        \n",
    "            \n",
    "#             for j in range(self.n3.size):\n",
    "#                 temp1 = self.n2[i].getActivation() * sigmoid_prime(self.n3[j].z)\n",
    "#                 temp2 = 0.0\n",
    "#                 for k in range(self.n4.size):\n",
    "#                     if k == target:\n",
    "#                         y = 1\n",
    "#                     else:\n",
    "#                         y = 0\n",
    "#                     temp2 += self.w3[j][k] * sigmoid_prime(self.n4[k].z) * 2.0 * (self.n4[k].getActivation() - y)\n",
    "                \n",
    "#                 self.w2_mod[i][j] += temp1 * temp2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#         for i in range(self.b3.size):\n",
    "            \n",
    "#             temp1 = sigmoid_prime(self.n3[i].z)\n",
    "#             temp2 = 0.0\n",
    "#             for j in range(self.b4.size):\n",
    "#                 if j == target:\n",
    "#                     y = 1\n",
    "#                 else:\n",
    "#                     y = 0\n",
    "#                 temp2 += self.w3[i][j] * sigmoid_prime(self.n4[j].z) * 2.0 * (self.n4[j].getActivation() - y)\n",
    "                \n",
    "#             self.b3_mod[i] += temp1 * temp2\n",
    "            \n",
    "        \n",
    "    \n",
    "#     def backProp_n2(self, target):\n",
    "#         y = 0\n",
    "#         for i in range(self.n1.size):  \n",
    "#             for j in range(self.n2.size):\n",
    "#                 temp1 = self.n1[i].getActivation() * sigmoid_prime(self.n2[j].z)\n",
    "\n",
    "\n",
    "                \n",
    "#                 temp2 = 0.0\n",
    "#                 for k in range(self.n3.size):\n",
    "#                     temp3 = 0.0\n",
    "#                     for l in range(self.n4.size):\n",
    "#                         if l == target:\n",
    "#                             y = 1\n",
    "#                         else:\n",
    "#                             y = 0\n",
    "#                         temp3 += self.w3[k][l] * sigmoid_prime(self.n4[l].z) * 2.0 * (self.n4[l].getActivation() - y)\n",
    "\n",
    "#                     temp3 *= self.w2[j][k] * sigmoid_prime(self.n3[k].z)\n",
    "#                     temp2 += temp3\n",
    "\n",
    "#                 self.w1_mod[i][j] += temp1 * temp2\n",
    "        \n",
    "#         for i in range(self.b2.size):\n",
    "#             temp1 = sigmoid_prime(self.n2[i].z)\n",
    "\n",
    "#             temp2 = 0.0\n",
    "            \n",
    "#             for j in range(self.b3.size):\n",
    "\n",
    "#                 temp3 = 0.0\n",
    "#                 for k in range(self.b4.size):\n",
    "#                     if k == target:\n",
    "#                         y = 1\n",
    "#                     else:\n",
    "#                         y = 0\n",
    "#                     temp3 += self.w3[j][k] * sigmoid_prime(self.n4[k].z) * 2.0 * (self.n4[k].getActivation() - y)\n",
    "\n",
    "#                 temp3 *= self.w2[i][j] * sigmoid_prime(self.n3[j].z)\n",
    "#                 temp2 += temp3\n",
    "\n",
    "#             self.b2_mod[i] += temp1 * temp2\n",
    "                    \n",
    "        \n",
    "#     def backProp(self, target):\n",
    "#         self.backProp_n4(target)\n",
    "#         self.backProp_n3(target)\n",
    "#         self.backProp_n2(target)\n",
    "    \n",
    "#     def runBatch(self, data, labels, startIdx = 0, batchSize=1000):\n",
    "        \n",
    "#         self.w3_mod = np.copy(self.w3)\n",
    "#         self.w3_mod.fill(0.0)\n",
    "        \n",
    "#         self.b4_mod = np.copy(self.b4)\n",
    "#         self.b4_mod.fill(0.0)\n",
    "\n",
    "        \n",
    "#         self.w2_mod = np.copy(self.w2)\n",
    "#         self.w2_mod.fill(0.0)\n",
    "        \n",
    "#         self.b3_mod = np.copy(self.b3)\n",
    "#         self.b3_mod.fill(0.0)\n",
    "        \n",
    "        \n",
    "#         self.w1_mod = np.copy(self.w1)\n",
    "#         self.w1_mod.fill(0.0)\n",
    "        \n",
    "#         self.b2_mod = np.copy(self.b2)\n",
    "#         self.b2_mod.fill(0.0)\n",
    "        \n",
    "#         loss = 0.0\n",
    "#         counter = 0\n",
    "#         for i in range(startIdx, startIdx + batchSize):\n",
    "#             if i % 10 == 0:\n",
    "#                 print(i)\n",
    "                \n",
    "#             self.initImage(data, i)\n",
    "#             self.runImage()\n",
    "#             loss += self.calcLoss(labels[i])\n",
    "#             if self.isCorrect(labels[i]):\n",
    "#                 counter += 1\n",
    "#             self.backProp(labels[i])\n",
    "\n",
    "\n",
    "#         # ASSUMING BATCH SIZE == 1000\n",
    "#         loss /= 10.0\n",
    "#         print(loss)\n",
    "#         print(counter / batchSize)\n",
    "\n",
    "#         # ASSUMING BATCH SIZE == 1000\n",
    "#         # ADJUSTED TO MATCH SLOW AHH NETWORK\n",
    "        \n",
    "#         # May be not needed\n",
    "#         self.w3_mod = np.divide(self.w3_mod, 10.0)\n",
    "#         self.w2_mod = np.divide(self.w2_mod, 10.0)\n",
    "#         self.w1_mod = np.divide(self.w1_mod, 10.0)\n",
    "#         self.b4_mod = np.divide(self.b4_mod, 10.0)\n",
    "#         self.b3_mod = np.divide(self.b3_mod, 10.0)\n",
    "#         self.b2_mod = np.divide(self.b2_mod, 10.0)\n",
    "        \n",
    "#         for i in range(self.n3.size):\n",
    "#             for j in range(self.n4.size):\n",
    "#                 self.w3[i][j] -= 3.0 * self.w3_mod[i][j]\n",
    "        \n",
    "#         for i in range(self.n2.size):\n",
    "#             for j in range(self.n3.size):\n",
    "#                 self.w2[i][j] -= 3.0 * self.w2_mod[i][j]\n",
    "        \n",
    "#         for i in range(self.n1.size):\n",
    "#             for j in range(self.n2.size):\n",
    "#                 self.w1[i][j] -= 3.0 * self.w1_mod[i][j]\n",
    "        \n",
    "#         for i in range(self.b4.size):\n",
    "#             self.b4[i] -= 3.0 * self.b4_mod[i]\n",
    "        \n",
    "#         for i in range(self.b3.size):\n",
    "#             self.b3[i] -= 3.0 * self.b3_mod[i]\n",
    "            \n",
    "#         for i in range(self.b2.size):\n",
    "#             self.b2[i] -= 3.0 * self.b2_mod[i]\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0328d088-9560-4745-9bbe-e6a8db11b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using the sigmoid function as our activation function\n",
    "def sigmoid(x):\n",
    "\n",
    "    x = np.float128(x)\n",
    "    \n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    \n",
    "    return expit(x) * (1.0 - expit(x))\n",
    "    \n",
    "\n",
    "class Network:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.a1 = np.zeros(784)\n",
    "        self.a2 = np.zeros(16)\n",
    "        self.a3 = np.zeros(16)[j]\n",
    "        self.a4 = np.zeros(10)\n",
    "\n",
    "        self.z2 = np.zeros(16)\n",
    "        self.z3 = np.zeros(16)\n",
    "        self.z4 = np.zeros(10)\n",
    "    \n",
    "    def setWeights(self, w1, w2, w3):\n",
    "        self.w1 = np.copy(w1)\n",
    "        self.w2 = np.copy(w2)\n",
    "        self.w3 = np.copy(w3)\n",
    "        \n",
    "    def setBiases(self, b2, b3, b4):\n",
    "        self.b2 = np.copy(b2)\n",
    "        self.b3 = np.copy(b3)\n",
    "        self.b4 = np.copy(b4)\n",
    "        \n",
    "    \n",
    "    # loads an image into the 1st layer\n",
    "    def initImage(self, data, index):\n",
    "        self.a1 = data[index].flatten()\n",
    "\n",
    "    def runImage(self):\n",
    "\n",
    "        # print(\"a\", self.a1.shape, self.a2.shape, self.a3.shape, self.a4.shape)\n",
    "        # print(\"z\", self.z2.shape, self.z3.shape, self.z4.shape)\n",
    "        self.z2 = np.dot(self.a1, self.w1) + self.b2\n",
    "        # print(\"z\", self.z2.shape, self.z3.shape, self.z4.shape)\n",
    "        self.a2 = expit(self.z2)\n",
    "        # print(\"z\", self.z2.shape, self.z3.shape, self.z4.shape)\n",
    "        \n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.w2) + self.b3\n",
    "        self.a3 = expit(self.z3)\n",
    "\n",
    "        # print(self.a1.shape, self.a2.shape, self.a3.shape, self.a4.shape)\n",
    "        # print(self.w1.shape, self.w2.shape, self.w3.shape)\n",
    "        \n",
    "        self.z4 = np.dot(self.a3, self.w3) + self.b4\n",
    "        self.a4 = expit(self.z4)\n",
    "\n",
    "    def calcLoss(self):\n",
    "        return np.linalg.norm(self.a4 - self.target_vector) ** 2.0\n",
    "    \n",
    "    def isCorrect(self):\n",
    "        return np.where(self.target_vector == 1)[0] == np.argmax(self.a4)\n",
    "            \n",
    "    \n",
    "    # Backprop\n",
    "    \n",
    "    def backProp_n4(self):\n",
    "        y = 0\n",
    "        self.w3_mod_cur = np.zeros((16, 10))\n",
    "\n",
    "        \n",
    "        for i in range(self.a3.size):\n",
    "            for j in range(self.a4.size):\n",
    "\n",
    "                if np.where(self.target_vector == 1)[0] == j:\n",
    "                    y = 1\n",
    "                else:\n",
    "                    y = 0\n",
    "\n",
    "                \n",
    "                if (i == 0): # calculate biases\n",
    "                    self.b4_mod[j] += sigmoid_prime(self.z4[j]) * 2.0 * (self.a4[j] - y)\n",
    "                \n",
    "                self.w3_mod_cur[i][j] = self.a3[i] * sigmoid_prime(self.z4[j]) * 2.0 * (self.a4[j] - y) # used for later calculations\n",
    "                self.w3_mod[i][j] += self.w3_mod_cur[i][j]\n",
    "                \n",
    "    \n",
    "    def backProp_n3(self):\n",
    "        self.w2_mod_cur = np.zeros((16, 16))\n",
    "        \n",
    "        temp_w3 = self.w3_mod_cur / self.a3[:, np.newaxis] # divide by a\n",
    "        temp_w3 *= self.w3 # multiply by w\n",
    "        # now temp_w3 is a matrix of del C / del a\n",
    "        \n",
    "        for i in range(self.a2.size):\n",
    "            for j in range(self.a3.size):\n",
    "                \n",
    "                temp = self.a2[i] * sigmoid_prime(self.z3[j])\n",
    "\n",
    "                temp2 = np.sum(temp_w3[j])\n",
    "\n",
    "                if i == 0: # calculate biases\n",
    "                    self.b3_mod[j] += sigmoid_prime(self.z3[j]) * temp2 # using w3 here (shhh!)\n",
    "\n",
    "                # print(self.w3_mod_cur.size)\n",
    "                # print(self.a3.size)\n",
    "                # print(i, j)\n",
    "                self.w2_mod_cur[i][j] = temp * temp2\n",
    "                self.w2_mod[i][j] += self.w2_mod_cur[i][j]\n",
    "\n",
    "                \n",
    "\n",
    "        \n",
    "    \n",
    "    def backProp_n2(self):\n",
    "        temp_w2 = self.w2_mod_cur / self.a2[:, np.newaxis] # divide by a\n",
    "        temp_w2 *= self.w2 # multiply by w\n",
    "        # now temp_w2 is a matrix of del C / del a\n",
    "        \n",
    "        for i in range(self.a1.size):\n",
    "            for j in range(self.a2.size):\n",
    "                \n",
    "                temp = self.a1[i] * sigmoid_prime(self.z2[j])\n",
    "\n",
    "                temp2 = np.sum(temp_w2[j])\n",
    "\n",
    "                if i == 0: # calculate biases\n",
    "                    self.b2_mod[j] += sigmoid_prime(self.z2[j]) * temp2 # using w3 here (shhh!)\n",
    "                    \n",
    "                self.w1_mod[i][j] += temp * temp2\n",
    "\n",
    "\n",
    "                    \n",
    "        \n",
    "    def backProp(self):\n",
    "        self.backProp_n4()\n",
    "        self.backProp_n3()\n",
    "        self.backProp_n2()\n",
    "    \n",
    "    def runBatch(self, data, labels, startIdx = 0, batchSize=100):\n",
    "        \n",
    "        self.w3_mod = np.copy(self.w3)\n",
    "        self.w3_mod.fill(0.0)\n",
    "        \n",
    "        self.b4_mod = np.copy(self.b4)\n",
    "        self.b4_mod.fill(0.0)\n",
    "        \n",
    "        self.w2_mod = np.copy(self.w2)\n",
    "        self.w2_mod.fill(0.0)\n",
    "        \n",
    "        self.b3_mod = np.copy(self.b3)\n",
    "        self.b3_mod.fill(0.0)\n",
    "        \n",
    "        self.w1_mod = np.copy(self.w1)\n",
    "        self.w1_mod.fill(0.0)\n",
    "        \n",
    "        self.b2_mod = np.copy(self.b2)\n",
    "        self.b2_mod.fill(0.0)\n",
    "\n",
    "        self.target_vector = np.zeros(10)\n",
    "        \n",
    "        loss = 0.0\n",
    "        counter = 0\n",
    "        for i in range(startIdx, startIdx + batchSize):\n",
    "            self.target_vector[labels[i]] = 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(i)\n",
    "            \n",
    "            self.initImage(data, i)\n",
    "            self.runImage()\n",
    "            loss += self.calcLoss()\n",
    "            if self.isCorrect():\n",
    "                counter += 1\n",
    "            self.backProp()\n",
    "\n",
    "            self.target_vector[labels[i]] = 0\n",
    "\n",
    "\n",
    "        # ASSUMING BATCH SIZE == 100\n",
    "        loss /= 100.0\n",
    "        print(loss)\n",
    "        print(counter / batchSize)\n",
    "\n",
    "        # ASSUMING BATCH SIZE == 100\n",
    "        # ADJUSTED TO MATCH SLOW AHH NETWORK\n",
    "        \n",
    "        # May be not needed\n",
    "        self.w3_mod = np.divide(self.w3_mod, 100.0)\n",
    "        self.w2_mod = np.divide(self.w2_mod, 100.0)\n",
    "        self.w1_mod = np.divide(self.w1_mod, 100.0)\n",
    "        self.b4_mod = np.divide(self.b4_mod, 100.0)\n",
    "        self.b3_mod = np.divide(self.b3_mod, 100.0)\n",
    "        self.b2_mod = np.divide(self.b2_mod, 100.0)\n",
    "        \n",
    "        self.w3 -= 3.0 * self.w3_mod\n",
    "        self.w2 -= 3.0 * self.w2_mod\n",
    "        self.w1 -= 3.0 * self.w1_mod\n",
    "        self.b4 -= 3.0 * self.b4_mod\n",
    "        self.b3 -= 3.0 * self.b3_mod\n",
    "        self.b2 -= 3.0 * self.b2_mod\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ca8ae6-2564-484b-9a74-c405ed8da370",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstNetwork = Network()\n",
    "firstNetwork.setWeights(l1Weights, l2Weights, l3Weights)\n",
    "firstNetwork.setBiases(l2Biases, l3Biases, l4Biases)\n",
    "#firstNetwork.setNeurons(l1, l2, l3, l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35e218c-f46d-46ad-9c4c-6f137affbefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets do a run with our loaded data\n",
    "\n",
    "# # Calculates activation of neurons in the second layer\n",
    "# for i in range(firstNetwork.n2.size): # Per 2nd layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n1.size): # Per 1st layer neuron\n",
    "#         sum += firstNetwork.n1[j].getActivation() * firstNetwork.w1[j][i]\n",
    "#     z = sum + firstNetwork.b2[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n2[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c447b4-fc4d-4a0f-a3c0-7b316d262a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(16):\n",
    "#     print(firstNetwork.n2[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f300331a-aee6-4532-be74-11fde8349732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3rd layer\n",
    "\n",
    "# for i in range(firstNetwork.n3.size): # Per 3rd layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n2.size): # Per 2nd layer neuron\n",
    "#         sum += firstNetwork.n2[j].getActivation() * firstNetwork.w2[j][i]\n",
    "#     z = sum + firstNetwork.b3[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n3[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95369675-fe14-42b3-9003-ea04c8f1088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(16):\n",
    "#     print(firstNetwork.n3[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5563a59-9210-4f36-b950-3626615d6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #head\n",
    "\n",
    "# for i in range(firstNetwork.n4.size): # Per 4th layer neuron\n",
    "#     sum = 0\n",
    "#     for j in range(firstNetwork.n3.size): # Per 3rd layer neuron\n",
    "#         sum += firstNetwork.n3[j].getActivation() * firstNetwork.w3[j][i]\n",
    "#     z = sum + firstNetwork.b4[i]\n",
    "#     a = sigmoid(z)\n",
    "#     firstNetwork.n4[i].setActivation(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33bdf44b-07f6-4f11-b782-028ae86cfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(firstNetwork.n4[i].getActivation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf271e11-ee5b-4fc5-944b-a9386aa46f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05a8df18-9920-4e1d-b6ca-7cd6c40d77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels[0])\n",
    "# print(firstNetwork.calcLoss(5))\n",
    "# print(getMaxNumber(firstNetwork.n4))\n",
    "# print(getMax(firstNetwork.n4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c17334e-cc13-4bed-bcb0-acbb260931b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(cost) / del(weight) == a(l-1) * sig'(z) * 2(a - y)\n",
    "# del(cost) / del(bias) == sig'(z) * 2(a - y)\n",
    "\n",
    "#### BACKPROP ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa65fa2f-80f9-42a7-ac48-dcf98a9715f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstNetwork.backProp_n4(5)\n",
    "# print(firstNetwork.w3_mod)\n",
    "# print(firstNetwork.b4_mod)\n",
    "\n",
    "# firstNetwork.backProp_n3()\n",
    "# print(firstNetwork.w2_mod)\n",
    "# print(firstNetwork.b3_mod)\n",
    "# firstNetwork.backProp_n2()\n",
    "# print(firstNetwork.w1_mod)\n",
    "# print(firstNetwork.b2_mod)\n",
    "\n",
    "# for i in range(784):\n",
    "#     for j in range(16):\n",
    "#         print(firstNetwork.w1_mod[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f981ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "4.723884981717088\n",
      "0.08\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "1.928823624595947\n",
      "0.14\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "1.1005391001069518\n",
      "0.12\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "0.9524473722351898\n",
      "0.13\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "0.9411234705213745\n",
      "0.14\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "0.95056241511204\n",
      "0.12\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "0.957575866479779\n",
      "0.09\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "0.9440724298027798\n",
      "0.14\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "0.9295335376605941\n",
      "0.19\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "0.9350153306259504\n",
      "0.15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(0, 1000, 100):\n",
    "    firstNetwork.runBatch(train_images, train_labels, i, 100)\n",
    "    \n",
    "# print(\"Starting Testing\")\n",
    "# firstNetwork.runBatch(test_images, test_labels) # TODO: Don't backpropagate on test runs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04b3089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1000, 10000, 1000):\n",
    "#     firstNetwork.runBatch(test_images, test_labels, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03292a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_labels[9999])\n",
    "# for neuron in firstNetwork.n4:\n",
    "#     print(neuron.getActivation())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84dedd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, 60000, 1000):\n",
    "#     firstNetwork.runBatch(train_images, train_labels, i)\n",
    "    \n",
    "# print(\"Starting Testing\")\n",
    "# for i in range(0, 10000, 1000):\n",
    "#     firstNetwork.runBatch(test_images, test_labels, i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60859c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_neuralnet",
   "language": "python",
   "name": "mnist_neuralnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
